## Amazon S3 (Simple Storage Service)

AWS S3 is a service that provides object-level storage. S3 **stores data as objects in buckets**. A bucket is combination of a bucket name, key, and version ID. It is used for data that doesn't change often i.e. ideal for storing static web content, media, backups, and archiving.

You can upload any type of file to AWS S3, and offers **unlimited storage space**. The maximum file size for an object is 5TB. However, when uploading more than 5GB, you must use **multi-part upload**.

Amazon S3 supports **global buckets**. Hence, each bucket name must be unique across all AWS accounts in all AWS Regions within a **partition**. A partition is a grouping of Regions. Buckets are defined at the **Region** level.

### Versioning

When you upload a file, you can set permissions to control visibility and access to it. You can also use the **versioning feature to track changes to your objects** over time (at bucket level).

For objects without versions, AWS will create a version marker if the object gets deleted.

### Object Model

Amazon S3 model is a **flat structure i.e. no hierarchy of subbuckets or subfolders**. However, it supports the concept of folders by using key name prefixes and delimiters.

```
http://testbucket.s3.amazonaws.com/2022-03-01/AmazonS3.html
http://testbucket.s3.amazonaws.com/2022-03-01/Cats.jpg
```

### Bucket policies

Unlike IAM policies which are attached to resources and users, S3 bucket policies can only be attached to S3 buckets. The policy that is placed on the bucket applies to every object in that bucket.

Bucket policies are useful for **cross-account access** i.e. other AWS accounts.

An IAM principal can access an S3 object if:

- The user IAM permissions ALLOW it OR the bucket policy ALLOWS it
- AND there is no explicit DENY

### Storage lifecycle

If you keep manually changing your objects from storage tier to storage tier, you can automate the process by configuring their Amazon S3 lifecycle. You can choose to automate between two types of actions:

- **Transition**: Define when objects should transition to another storage class
- **Expiration**: Define when objects expire and should be permanently deleted

### Replication

To use replication, you need to **enable versioning in source and destination buckets**. Two kinds of replication:

- Cross-Region Replication (CRR)
- Same-Region Replication (SRR)

Copying is done asynchronously.

## Storage classes

With AWS S3, you pay for what you use. You can choose a range of storage classes to selet a fit for your business and cost needs. When selecting a storage class, consider the following:

- How often you plan to retrieve your data
- How available you need your data to be

### Standard

- Designed for frequently used accessed data
- Stores data in a **minimum of three Availability Zones**

Provides high availability for objects. Makes a good choice for a wide range of use cases, including websites, content distribution, and data analytics.

### Standard-Infrequent Access (S3 Standard-IA)

- Ideal for infrequently accessed data
- Similar to Standard but has a lower storage price but higher retrieval price

### One Zone-Infrequent Access (S3 One Zone-IA)

Stores data in a single Availability Zone. Has a lower storage price than S3 Standard-IA. This makes a good storage class if:

- You want to save costs on storage
- You can easily reproduce your data in the event of an Availability Zone failure

### Intelligent-Tiering

- Ideal for data with unknown or changing access patterns
- Requires a small monthly monitoring and automation fee per object
- No retrieval charges

In this storage class, S3 monitors objects' access patterns:

- Frequent access tier
- Infrequent access tier if objects not accessed for 30 days
- Archive Instant access tier if objects not accessed for 90 days

### Glacier Instant Retrieval

- Works well for archived data that requires immediate access
- Can retrieve objects within a few miliseconds

### Glacier Flexible Retrival

- Low-cost storage designed for data archiving
- Able to retrieve objects within a few minutes to hours

### Glacier Deep Archive

- Lowest-cost object storage class ideal for archiving
- Able to retrieve objects within 12 hours

### Outposts

- Creates S3 buckets on Amazon S3 Outposts
- Makes it easier to retrieve, store, and access data on AWS Outposts

AWS S3 Outposts delivers object storage to your on-premises AWS Outposts environment. It is a pool of AWS compute and storage capacity deployed at a customer site. AWS monitors, operates, and manages this capacity as part of an AWS Region.

It is designed to store data durably and redundantly across multiple devices and servers on your Outposts. It works well for workloads with local data residency requirements that must satisfy demanding performance needs by keeping data close to on-premise applications.
